{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_train.txt', 'full_test.txt']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/movie_data/movie_data\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true,
    "_uuid": "440890c4325dfc2afdb0e2d2513c373ff9f523e4"
   },
   "outputs": [],
   "source": [
    "reviews_train = []\n",
    "for line in open('../input/movie_data/movie_data/full_train.txt', 'r'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('../input/movie_data/movie_data/full_test.txt', 'r'):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n",
    "    \n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true,
    "_uuid": "56e3ed672c5e10feb0420a9d5a3f165fee6757ee"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "trusted": true,
    "_uuid": "cd0c4b24f8dd80147a3c532aaad0354e227c1c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  86374\n"
     ]
    }
   ],
   "source": [
    "baseline_vectorizer = CountVectorizer(binary=True)\n",
    "baseline_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(baseline_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", baseline_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "trusted": true,
    "_uuid": "3c4382f0f979775bffe64eb3a0fd4e380e0f48a2"
   },
   "outputs": [],
   "source": [
    "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
    "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "trusted": true,
    "_uuid": "7ecf949a36d6f7a1934416203c77d6d96ebc6e21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8701333333333333\nAccuracy for C=0.05: 0.8810666666666667\nAccuracy for C=0.25: 0.8872\nAccuracy for C=0.5: 0.8832\nAccuracy for C=1: 0.8826666666666667\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_baseline, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "trusted": true,
    "_uuid": "92ad90e62dbd4614d9c0987fd31d0fe82e9106f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value using for C:  0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87528\n"
     ]
    }
   ],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test_baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f8f7d6b031fcbe53e38fbfdbcafc7c7153097b4"
   },
   "source": [
    "**Remove stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "trusted": true,
    "_uuid": "001b133d89794bcb0234dac8c377806716585002"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "trusted": true,
    "_uuid": "e03b8f1679d1e312d996dcb21a784838d91543d1"
   },
   "outputs": [],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "trusted": true,
    "_uuid": "616508ae90c6ddfe76f7405b7366d7de5a55308a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  86357\n"
     ]
    }
   ],
   "source": [
    "stopword_vectorizer = CountVectorizer(binary=True)\n",
    "stopword_vectorizer.fit(no_stop_words_train)\n",
    "print(\"Size of dictionary: \", len(stopword_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", stopword_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "trusted": true,
    "_uuid": "f617964395eec60b85ee23eab8c536488f6ec349"
   },
   "outputs": [],
   "source": [
    "X = stopword_vectorizer.transform(no_stop_words_train)\n",
    "X_test = stopword_vectorizer.transform(no_stop_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "trusted": true,
    "_uuid": "1fe72315991aaa0e32d78ce8dffcae192136fa6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8802666666666666\nAccuracy for C=0.05: 0.8872\nAccuracy for C=0.25: 0.8829333333333333\nAccuracy for C=0.5: 0.8824\nAccuracy for C=1: 0.8805333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "trusted": true,
    "_uuid": "130f1422884152e4e665baafb460e633dc8c5873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value using for C:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87796\n"
     ]
    }
   ],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "trusted": true,
    "_uuid": "7b824e3f534b06636fba77dd6f03b9aecd151a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.8804602077347948)\n('perfect', 0.7432126467211464)\n('great', 0.6827123379158221)\n('enjoyable', 0.6258012729095954)\n('wonderful', 0.6087005468520406)\n('amazing', 0.5903051684301432)\n('superb', 0.5819249705470795)\n('enjoyed', 0.5738280746218912)\n('favorite', 0.5729119064279654)\n('today', 0.5695702126588372)\n\n\n\n('worst', -1.3815488254103057)\n('waste', -1.1508659423383225)\n('awful', -0.9480172016161376)\n('boring', -0.8621169054367182)\n('disappointment', -0.8452674232927643)\n('poorly', -0.8108798474450853)\n('bad', -0.7483155792783629)\n('disappointing', -0.7437232895600603)\n('dull', -0.7427827816056617)\n('poor', -0.7347383332416065)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        stopword_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b03fbf99af5e47b9a94297456d2b9230a850686"
   },
   "source": [
    "**Lemmatization**\n",
    "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "trusted": true,
    "_uuid": "1c4db0d273a3a1c8f378130a5e79eaaa32fb3d35"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def get_lemmatized_text(corpus):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "trusted": true,
    "_uuid": "d824e25eea5788f3c5b91acaa7767e55ff3a24a9"
   },
   "outputs": [],
   "source": [
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "trusted": true,
    "_uuid": "b5d93a1407466f25ff5c9e14e3b3ab6f0e6f4326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  79651\n"
     ]
    }
   ],
   "source": [
    "lemmatize_vectorizer = CountVectorizer(binary=True)\n",
    "lemmatize_vectorizer.fit(lemmatized_reviews_train)\n",
    "print(\"Size of dictionary: \", len(lemmatize_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", lemmatize_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "trusted": true,
    "_uuid": "6bd3e5aa5c66b7de8a9382751196abf498797795"
   },
   "outputs": [],
   "source": [
    "X = lemmatize_vectorizer.transform(lemmatized_reviews_train)\n",
    "X_test = lemmatize_vectorizer.transform(lemmatized_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "trusted": true,
    "_uuid": "44511cc9b69eda0fd5035791c872df22add34a21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8725333333333334\nAccuracy for C=0.05: 0.8805333333333333\nAccuracy for C=0.25: 0.8770666666666667\nAccuracy for C=0.5: 0.8749333333333333\nAccuracy for C=1: 0.8712\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "trusted": true,
    "_uuid": "4a676c42185b4b7f04cded238d0c142ffbe41883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value using for C:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87812\n"
     ]
    }
   ],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "trusted": true,
    "_uuid": "f89a7c7c8455f88113bab88d47543c0e28dfcbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.9084688438231432)\n('perfect', 0.7578961370927583)\n('great', 0.6625676769834377)\n('amazing', 0.640343872065302)\n('favorite', 0.6152024212167753)\n('loved', 0.5902433107905792)\n('enjoyable', 0.5854735864118813)\n('wonderful', 0.5826678128955866)\n('today', 0.572724060958529)\n('superb', 0.5586111531811624)\n\n\n\n('worst', -1.3157214030538866)\n('waste', -1.0804376505618578)\n('awful', -1.067378862497543)\n('boring', -0.8524944764937644)\n('poorly', -0.8219956324605929)\n('disappointing', -0.7046667736899124)\n('terrible', -0.6997226931439782)\n('disappointment', -0.6960900492360738)\n('poor', -0.6891741876904484)\n('dull', -0.6851276557577579)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        lemmatize_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf94883bdf5c28de2a42d3da8b26c9aecb3624e5"
   },
   "source": [
    "**Stemming**\nhttps://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "trusted": true,
    "_uuid": "7f9dfe3572ab2e1781c9ec13477871b4b9f695be"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "trusted": true,
    "_uuid": "268804b825dc86597e80603034028a6323c1a721"
   },
   "outputs": [],
   "source": [
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "trusted": true,
    "_uuid": "02b45ccaafe11cb9156b7374ecf5d8ec9137e96b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  66220\n"
     ]
    }
   ],
   "source": [
    "stemm_vectorizer = CountVectorizer(binary=True)\n",
    "stemm_vectorizer.fit(stemmed_reviews_train)\n",
    "print(\"Size of dictionary: \", len(stemm_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", stemm_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "trusted": true,
    "_uuid": "5c1023addd308e8f2d5c9fc066477657bb64dc97"
   },
   "outputs": [],
   "source": [
    "X = stemm_vectorizer.transform(stemmed_reviews_train)\n",
    "X_test = stemm_vectorizer.transform(stemmed_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "trusted": true,
    "_uuid": "e749dcb80210e9b929e727b9f6ad59d2731fb90f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8672\nAccuracy for C=0.05: 0.8754666666666666\nAccuracy for C=0.25: 0.8725333333333334\nAccuracy for C=0.5: 0.8685333333333334\nAccuracy for C=1: 0.8656\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "trusted": true,
    "_uuid": "963a9cf89ce5d2e788657220e7335fe81aeee3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value using for C:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87648\n"
     ]
    }
   ],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "trusted": true,
    "_uuid": "1fab870c9fbb02dd503883f206a7e4960a88e3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excel', 0.9624390848254747)\n('perfect', 0.7969511879296894)\n('great', 0.6771041782527951)\n('favorit', 0.6421194642722267)\n('superb', 0.595193768080948)\n('refresh', 0.5871849749417393)\n('enjoy', 0.5657464323780484)\n('today', 0.5636867721494785)\n('highli', 0.5627563945597394)\n('perfectli', 0.5597418079328637)\n\n\n\n('worst', -1.3279368675211911)\n('wast', -1.1230465034330532)\n('aw', -0.974097904944865)\n('dull', -0.8180963081852665)\n('poorli', -0.8115788562939348)\n('bore', -0.771575721698185)\n('disappoint', -0.7681881659478987)\n('poor', -0.753727826733088)\n('wors', -0.7050334555348351)\n('bad', -0.6753253325883405)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        stemm_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "140d85693fd55aed4c2f6f4c6aca3cc349ea36ff"
   },
   "source": [
    "**Using n-grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "trusted": true,
    "_uuid": "3ce2b40c4b5fe7f27512cb10ad3799c7e2d0e8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  1532909\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(ngram_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", ngram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "trusted": true,
    "_uuid": "779f5e05b188a152d69ade647c397b3a99043359"
   },
   "outputs": [],
   "source": [
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "trusted": true,
    "_uuid": "fab6ba04b1d860801ac10f06a7a5332c7a671b71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8850666666666667\nAccuracy for C=0.05: 0.8952\nAccuracy for C=0.25: 0.8952\nAccuracy for C=0.5: 0.8952\nAccuracy for C=1: 0.8941333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "trusted": true,
    "_uuid": "327714a5bc853501db58d4f247e65301927d1bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value using for C:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89412\n"
     ]
    }
   ],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "trusted": true,
    "_uuid": "b8004f72ed3fd236ab68105625dbf7a05c0d326b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.7171399759506399)\n('great', 0.6532125292060386)\n('perfect', 0.6385149399533783)\n('wonderful', 0.5499892406590796)\n('amazing', 0.49769641145502413)\n('superb', 0.47393847397792827)\n('today', 0.4320437625802879)\n('enjoyable', 0.43101133809667325)\n('enjoyed', 0.4139699928555225)\n('loved', 0.4056242228452547)\n\n\n\n('worst', -0.9192909223109731)\n('awful', -0.8711853969273665)\n('waste', -0.7360252459846508)\n('bad', -0.7149357190939444)\n('boring', -0.7084538590791247)\n('poor', -0.6621730464393614)\n('the worst', -0.6427910150433388)\n('terrible', -0.6036168389487931)\n('poorly', -0.586304979171294)\n('dull', -0.5467282170513686)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        ngram_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a47d7a4a136479bb079127ead0d580a258ec9389"
   },
   "source": [
    "**TF-IDF (term frequency-inverse data frequency)**\n",
    "https://buhrmann.github.io/tfidf-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "trusted": true,
    "_uuid": "93106652011b51f0be1654c6f70831a272b3820b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  1777206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', analyzer='word', ngram_range=(1, 2))\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(tfidf_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "trusted": true,
    "_uuid": "57591329558be2bd3ecb8c0a86b93037757e67bb"
   },
   "outputs": [],
   "source": [
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "trusted": true,
    "_uuid": "3c1aa539a1eeba9a5e46ca70c36bb402e8531dd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8245333333333333\nAccuracy for C=0.05: 0.8344\nAccuracy for C=0.25: 0.8581333333333333\nAccuracy for C=0.5: 0.8749333333333333\nAccuracy for C=1: 0.8824\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "trusted": true,
    "_uuid": "a17696a9cb6f5f74c61aa6dee87f377ad88ad113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value using for C:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.86968\n"
     ]
    }
   ],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "trusted": true,
    "_uuid": "96a01432e4cdc87d00f7e0bf4a68b83671278441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('great', 8.96394765251946)\n('excellent', 6.194993740811503)\n('best', 5.971685753815957)\n('love', 5.169923358869189)\n('wonderful', 4.9498828867269)\n('perfect', 4.323149888836021)\n('amazing', 4.251834241511996)\n('favorite', 4.102620094326023)\n('fun', 3.9116056430903616)\n('loved', 3.793782384717356)\n\n\n\n('bad', -9.965354117289802)\n('worst', -8.94865946902623)\n('awful', -6.2635527310533)\n('waste', -5.881233218778964)\n('boring', -5.690736298978455)\n('poor', -5.349430678416386)\n('worse', -4.80313370729508)\n('terrible', -4.781690638038636)\n('script', -4.4218678082570095)\n('minutes', -4.348345354652207)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        tfidf_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "80b188699fef8f6736345d5683877f12bad466ea"
   },
   "source": [
    "**Using linear Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "trusted": true,
    "_uuid": "fcc5859c4b1b54a346e5bd2fac0dcbb8c3ff6824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  1532909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc_ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "lsvc_ngram_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(lsvc_ngram_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", lsvc_ngram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "trusted": true,
    "_uuid": "538244f0ff4bbf7887e98f6ea466c5f650ce41b1"
   },
   "outputs": [],
   "source": [
    "X = lsvc_ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = lsvc_ngram_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "trusted": true,
    "_uuid": "58f8f9cd860cc903c24dc3d896039f492ee8d3c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8904\nAccuracy for C=0.05: 0.8912\nAccuracy for C=0.25: 0.8898666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.8901333333333333\nAccuracy for C=1: 0.8898666666666667\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lsvc = LinearSVC(C=i)\n",
    "    lsvc.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lsvc.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "trusted": true,
    "_uuid": "9d4c3d5e871f1366e1864bc0871861c1bdac6044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value using for C:  0.05\nFinal Accuracy: 0.89172\n"
     ]
    }
   ],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LinearSVC(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "trusted": true,
    "_uuid": "83fcb4d2c09419739fcb4a1919f5bc3db56d79be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.2840498601198245)\n('perfect', 0.2043035423297832)\n('great', 0.20069819503674716)\n('enjoyable', 0.19622293623041642)\n('superb', 0.18114288427951528)\n('wonderful', 0.1786807689008129)\n('today', 0.1664913876944546)\n('amazing', 0.16244509859458678)\n('brilliant', 0.15540396579820856)\n('definitely worth', 0.152865317341006)\n\n\n\n('worst', -0.32395233894228503)\n('awful', -0.31880229263368215)\n('boring', -0.29843532714545445)\n('waste', -0.2574711423043509)\n('terrible', -0.2573343762893931)\n('bad', -0.2374586177099922)\n('the worst', -0.23164610072638653)\n('disappointing', -0.2257264154994067)\n('dull', -0.22216393598426507)\n('poor', -0.22156403436822783)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        lsvc_ngram_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "trusted": true,
    "_uuid": "75d7b348909eccaebd6fbff063e683e43bec27e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos prediction: [1]\n"
     ]
    }
   ],
   "source": [
    "pos = [\"I've seen this story before but my kids haven't. Boy with troubled past joins military, faces his past, falls in love and becomes a man. \"\n",
    "       \"The mentor this time is played perfectly by Kevin Costner; An ordinary man with common everyday problems who lives an extraordinary \"\n",
    "       \"conviction, to save lives. After losing his team he takes a teaching position training the next generation of heroes. The young troubled \"\n",
    "       \"recruit is played by Kutcher. While his scenes with the local love interest are a tad stiff and don't generate enough heat to melt butter, \"\n",
    "       \"he compliments Costner well. I never really understood Sela Ward as the neglected wife and felt she should of wanted Costner to quit out of \"\n",
    "       \"concern for his safety as opposed to her selfish needs. But her presence on screen is a pleasure. The two unaccredited stars of this movie \"\n",
    "       \"are the Coast Guard and the Sea. Both powerful forces which should not be taken for granted in real life or this movie. The movie has some \"\n",
    "       \"slow spots and could have used the wasted 15 minutes to strengthen the character relationships. But it still works. The rescue scenes are \"\n",
    "       \"intense and well filmed and edited to provide maximum impact. This movie earns the audience applause. And the applause of my two sons.\"]\n",
    "print(\"Pos prediction: {}\". format(lsvc.predict(lsvc_ngram_vectorizer.transform(pos))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "trusted": true,
    "_uuid": "e896da4f0c80379c18541d35eaa1245449c47f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "neg = [\"We do not want to send out an e-mail with a subject line that recipient(s) feel like avoiding.\"\"\n",
    "       \"Think about your own reaction on e-mails with negative subject lines;\"\n",
    "       \"do you even feel like opening them? Example, instead of a subject line that says ‘Delay in\" \n",
    "       \"ABC project schedule,’ the subject line can be ‘Changes in ABC project schedule.'\"]\n",
    "print(\"Neg prediction: {}\". format(lsvc.predict(lsvc_ngram_vectorizer.transform(neg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "b6ee0d1c579a6881ee693614d9084d089d225cef"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

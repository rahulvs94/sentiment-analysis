{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/movie_data/movie_data\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['full_test.txt', 'full_train.txt']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nimport re\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 83,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "440890c4325dfc2afdb0e2d2513c373ff9f523e4"
      },
      "cell_type": "code",
      "source": "reviews_train = []\nfor line in open('../input/movie_data/movie_data/full_train.txt', 'r'):\n    \n    reviews_train.append(line.strip())\n    \nreviews_test = []\nfor line in open('../input/movie_data/movie_data/full_test.txt', 'r'):\n    \n    reviews_test.append(line.strip())\n    \ntarget = [1 if i < 12500 else 0 for i in range(25000)]",
      "execution_count": 84,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56e3ed672c5e10feb0420a9d5a3f165fee6757ee"
      },
      "cell_type": "code",
      "source": "import re\n\nREPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\nREPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\nNO_SPACE = \"\"\nSPACE = \" \"\n\ndef preprocess_reviews(reviews):\n    \n    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n    \n    return reviews\n\nreviews_train_clean = preprocess_reviews(reviews_train)\nreviews_test_clean = preprocess_reviews(reviews_test)",
      "execution_count": 85,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd0c4b24f8dd80147a3c532aaad0354e227c1c81"
      },
      "cell_type": "code",
      "source": "baseline_vectorizer = CountVectorizer(binary=True)\nbaseline_vectorizer.fit(reviews_train_clean)\nprint(\"Size of dictionary: \", len(baseline_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", baseline_vectorizer.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c4382f0f979775bffe64eb3a0fd4e380e0f48a2"
      },
      "cell_type": "code",
      "source": "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\nX_test_baseline = baseline_vectorizer.transform(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ecf949a36d6f7a1934416203c77d6d96ebc6e21"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X_baseline, target, train_size = 0.85)\nscore = []\nc = [0.01, 0.05, 0.25, 0.5, 1]\nfor i in c:\n    lr = LogisticRegression(C=i)\n    lr.fit(X_train, y_train)\n    score.append(accuracy_score(y_val, lr.predict(X_val)))\n    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92ad90e62dbd4614d9c0987fd31d0fe82e9106f6"
      },
      "cell_type": "code",
      "source": "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\nfinal_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\nfinal_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test_baseline)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5f8f7d6b031fcbe53e38fbfdbcafc7c7153097b4"
      },
      "cell_type": "markdown",
      "source": "**Remove stop words**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "001b133d89794bcb0234dac8c377806716585002"
      },
      "cell_type": "code",
      "source": "from nltk.corpus import stopwords\n\nenglish_stop_words = stopwords.words('english')\n\ndef remove_stop_words(corpus):\n    removed_stop_words = []\n    for review in corpus:\n        removed_stop_words.append(\n            ' '.join([word for word in review.split() \n                      if word not in english_stop_words])\n        )\n    return removed_stop_words",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e03b8f1679d1e312d996dcb21a784838d91543d1"
      },
      "cell_type": "code",
      "source": "no_stop_words_train = remove_stop_words(reviews_train_clean)\nno_stop_words_test = remove_stop_words(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "616508ae90c6ddfe76f7405b7366d7de5a55308a"
      },
      "cell_type": "code",
      "source": "stopword_vectorizer = CountVectorizer(binary=True)\nstopword_vectorizer.fit(no_stop_words_train)\nprint(\"Size of dictionary: \", len(stopword_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", stopword_vectorizer.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f617964395eec60b85ee23eab8c536488f6ec349"
      },
      "cell_type": "code",
      "source": "X = stopword_vectorizer.transform(no_stop_words_train)\nX_test = stopword_vectorizer.transform(no_stop_words_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fe72315991aaa0e32d78ce8dffcae192136fa6a"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\nscore = []\nc = [0.01, 0.05, 0.25, 0.5, 1]\nfor i in c:\n    lr = LogisticRegression(C=i)\n    lr.fit(X_train, y_train)\n    score.append(accuracy_score(y_val, lr.predict(X_val)))\n    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "130f1422884152e4e665baafb460e633dc8c5873"
      },
      "cell_type": "code",
      "source": "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\nfinal_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\nfinal_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b824e3f534b06636fba77dd6f03b9aecd151a1d"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        stopword_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3b03fbf99af5e47b9a94297456d2b9230a850686"
      },
      "cell_type": "markdown",
      "source": "**Lemmatization**\nhttps://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c4db0d273a3a1c8f378130a5e79eaaa32fb3d35"
      },
      "cell_type": "code",
      "source": "from nltk.stem import WordNetLemmatizer\n\ndef get_lemmatized_text(corpus):\n    lemmatizer = WordNetLemmatizer()\n    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d824e25eea5788f3c5b91acaa7767e55ff3a24a9"
      },
      "cell_type": "code",
      "source": "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\nlemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5d93a1407466f25ff5c9e14e3b3ab6f0e6f4326"
      },
      "cell_type": "code",
      "source": "lemmatize_vectorizer = CountVectorizer(binary=True)\nlemmatize_vectorizer.fit(lemmatized_reviews_train)\nprint(\"Size of dictionary: \", len(lemmatize_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", lemmatize_vectorizer.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6bd3e5aa5c66b7de8a9382751196abf498797795"
      },
      "cell_type": "code",
      "source": "X = lemmatize_vectorizer.transform(lemmatized_reviews_train)\nX_test = lemmatize_vectorizer.transform(lemmatized_reviews_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "44511cc9b69eda0fd5035791c872df22add34a21"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\nscore = []\nc = [0.01, 0.05, 0.25, 0.5, 1]\nfor i in c:\n    lr = LogisticRegression(C=i)\n    lr.fit(X_train, y_train)\n    score.append(accuracy_score(y_val, lr.predict(X_val)))\n    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a676c42185b4b7f04cded238d0c142ffbe41883"
      },
      "cell_type": "code",
      "source": "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\nfinal_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\nfinal_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f89a7c7c8455f88113bab88d47543c0e28dfcbe6"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        lemmatize_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cf94883bdf5c28de2a42d3da8b26c9aecb3624e5"
      },
      "cell_type": "markdown",
      "source": "**Stemming**\nhttps://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f9dfe3572ab2e1781c9ec13477871b4b9f695be"
      },
      "cell_type": "code",
      "source": "from nltk.stem.porter import PorterStemmer\n\ndef get_stemmed_text(corpus):\n    stemmer = PorterStemmer()\n    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "268804b825dc86597e80603034028a6323c1a721"
      },
      "cell_type": "code",
      "source": "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\nstemmed_reviews_test = get_stemmed_text(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02b45ccaafe11cb9156b7374ecf5d8ec9137e96b"
      },
      "cell_type": "code",
      "source": "stemm_vectorizer = CountVectorizer(binary=True)\nstemm_vectorizer.fit(stemmed_reviews_train)\nprint(\"Size of dictionary: \", len(stemm_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", stemm_vectorizer.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c1023addd308e8f2d5c9fc066477657bb64dc97"
      },
      "cell_type": "code",
      "source": "X = stemm_vectorizer.transform(stemmed_reviews_train)\nX_test = stemm_vectorizer.transform(stemmed_reviews_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e749dcb80210e9b929e727b9f6ad59d2731fb90f"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\nscore = []\nc = [0.01, 0.05, 0.25, 0.5, 1]\nfor i in c:\n    lr = LogisticRegression(C=i)\n    lr.fit(X_train, y_train)\n    score.append(accuracy_score(y_val, lr.predict(X_val)))\n    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "963a9cf89ce5d2e788657220e7335fe81aeee3b6"
      },
      "cell_type": "code",
      "source": "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\nfinal_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\nfinal_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fab870c9fbb02dd503883f206a7e4960a88e3cc"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        stemm_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "140d85693fd55aed4c2f6f4c6aca3cc349ea36ff"
      },
      "cell_type": "markdown",
      "source": "**Using n-grams**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ce2b40c4b5fe7f27512cb10ad3799c7e2d0e8d0"
      },
      "cell_type": "code",
      "source": "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\nngram_vectorizer.fit(reviews_train_clean)\nprint(\"Size of dictionary: \", len(ngram_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", ngram_vectorizer.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "779f5e05b188a152d69ade647c397b3a99043359"
      },
      "cell_type": "code",
      "source": "X = ngram_vectorizer.transform(reviews_train_clean)\nX_test = ngram_vectorizer.transform(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fab6ba04b1d860801ac10f06a7a5332c7a671b71"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\nscore = []\nc = [0.01, 0.05, 0.25, 0.5, 1]\nfor i in c:\n    lr = LogisticRegression(C=i)\n    lr.fit(X_train, y_train)\n    score.append(accuracy_score(y_val, lr.predict(X_val)))\n    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "327714a5bc853501db58d4f247e65301927d1bcf"
      },
      "cell_type": "code",
      "source": "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\nfinal_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\nfinal_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8004f72ed3fd236ab68105625dbf7a05c0d326b"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        ngram_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a47d7a4a136479bb079127ead0d580a258ec9389"
      },
      "cell_type": "markdown",
      "source": "**TF-IDF (term frequency-inverse term frequency)**\nhttps://buhrmann.github.io/tfidf-analysis.html"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93106652011b51f0be1654c6f70831a272b3820b"
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(stop_words='english', analyzer='word', ngram_range=(1, 2))\ntfidf_vectorizer.fit(reviews_train_clean)\nprint(\"Size of dictionary: \", len(tfidf_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", tfidf_vectorizer.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57591329558be2bd3ecb8c0a86b93037757e67bb"
      },
      "cell_type": "code",
      "source": "X = tfidf_vectorizer.transform(reviews_train_clean)\nX_test = tfidf_vectorizer.transform(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c1aa539a1eeba9a5e46ca70c36bb402e8531dd8"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\nscore = []\nc = [0.01, 0.05, 0.25, 0.5, 1]\nfor i in c:\n    lr = LogisticRegression(C=i)\n    lr.fit(X_train, y_train)\n    score.append(accuracy_score(y_val, lr.predict(X_val)))\n    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a17696a9cb6f5f74c61aa6dee87f377ad88ad113"
      },
      "cell_type": "code",
      "source": "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\nfinal_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\nfinal_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96a01432e4cdc87d00f7e0bf4a68b83671278441"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        tfidf_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "80b188699fef8f6736345d5683877f12bad466ea"
      },
      "cell_type": "markdown",
      "source": "**Using linear Support Vector Machine**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fcc5859c4b1b54a346e5bd2fac0dcbb8c3ff6824"
      },
      "cell_type": "code",
      "source": "from sklearn.svm import LinearSVC\n\nlsvc_ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\nlsvc_ngram_vectorizer.fit(reviews_train_clean)\nprint(\"Size of dictionary: \", len(lsvc_ngram_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", lsvc_ngram_vectorizer.get_feature_names())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "538244f0ff4bbf7887e98f6ea466c5f650ce41b1"
      },
      "cell_type": "code",
      "source": "X = lsvc_ngram_vectorizer.transform(reviews_train_clean)\nX_test = lsvc_ngram_vectorizer.transform(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58f8f9cd860cc903c24dc3d896039f492ee8d3c3"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\nscore = []\nc = [0.01, 0.05, 0.25, 0.5, 1]\nfor i in c:\n    lsvc = LinearSVC(C=i)\n    lsvc.fit(X_train, y_train)\n    score.append(accuracy_score(y_val, lsvc.predict(X_val)))\n    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d4c3d5e871f1366e1864bc0871861c1bdac6044"
      },
      "cell_type": "code",
      "source": "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\nfinal_model = LinearSVC(C=c[np.where(max(score) == score)[0][0]])\nfinal_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83fcb4d2c09419739fcb4a1919f5bc3db56d79be"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        lsvc_ngram_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75d7b348909eccaebd6fbff063e683e43bec27e8"
      },
      "cell_type": "code",
      "source": "pos = [\"I've seen this story before but my kids haven't. Boy with troubled past joins military, faces his past, falls in love and becomes a man. \"\n       \"The mentor this time is played perfectly by Kevin Costner; An ordinary man with common everyday problems who lives an extraordinary \"\n       \"conviction, to save lives. After losing his team he takes a teaching position training the next generation of heroes. The young troubled \"\n       \"recruit is played by Kutcher. While his scenes with the local love interest are a tad stiff and don't generate enough heat to melt butter, \"\n       \"he compliments Costner well. I never really understood Sela Ward as the neglected wife and felt she should of wanted Costner to quit out of \"\n       \"concern for his safety as opposed to her selfish needs. But her presence on screen is a pleasure. The two unaccredited stars of this movie \"\n       \"are the Coast Guard and the Sea. Both powerful forces which should not be taken for granted in real life or this movie. The movie has some \"\n       \"slow spots and could have used the wasted 15 minutes to strengthen the character relationships. But it still works. The rescue scenes are \"\n       \"intense and well filmed and edited to provide maximum impact. This movie earns the audience applause. And the applause of my two sons.\"]\nprint(\"Pos prediction: {}\". format(lsvc.predict(lsvc_ngram_vectorizer.transform(pos))))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e896da4f0c80379c18541d35eaa1245449c47f45"
      },
      "cell_type": "code",
      "source": "neg = [\"We do not want to send out an e-mail with a subject line that recipient(s) feel like avoiding.\"\"\n       \"Think about your own reaction on e-mails with negative subject lines;\"\n       \"do you even feel like opening them? Example, instead of a subject line that says ‘Delay in\" \n       \"ABC project schedule,’ the subject line can be ‘Changes in ABC project schedule.'\"]\nprint(\"Neg prediction: {}\". format(lsvc.predict(lsvc_ngram_vectorizer.transform(neg))))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b6ee0d1c579a6881ee693614d9084d089d225cef"
      },
      "cell_type": "markdown",
      "source": "**Using Naive Bayes**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "89248cb664327b470b795cf9bf7f8bb8bb51166c"
      },
      "cell_type": "code",
      "source": "from nltk.corpus import stopwords\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix\n\nenglish_stop_words = stopwords.words('english')\n\ndef remove_stop_words(corpus):\n    removed_stop_words = []\n    for review in corpus:\n        removed_stop_words.append(\n            ' '.join([word for word in review.split() \n                      if word not in english_stop_words])\n        )\n    return removed_stop_words",
      "execution_count": 73,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9606dbbc701717125c5a60b02e3f66c73291d03f"
      },
      "cell_type": "code",
      "source": "no_stop_words_train = remove_stop_words(reviews_train_clean)\nno_stop_words_test = remove_stop_words(reviews_test_clean)",
      "execution_count": 74,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e77f1784243fedc232ec40d5c284c0f1afcf0265"
      },
      "cell_type": "code",
      "source": "stopword_vectorizer = CountVectorizer(binary=True)\nstopword_vectorizer.fit(no_stop_words_train)\nprint(\"Size of dictionary: \", len(stopword_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", stopword_vectorizer.get_feature_names())",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Size of dictionary:  86357\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5112384eb2c5c9deeee3eed5be884f3bd93c8af3"
      },
      "cell_type": "code",
      "source": "X_train = stopword_vectorizer.transform(no_stop_words_train)\nX_test = stopword_vectorizer.transform(no_stop_words_test)",
      "execution_count": 76,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e29781f73a8d6313947820937298c907cf95487"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, target, train_size = 0.85)\n\nmnb = MultinomialNB()\nparameters = {\n    'alpha':list(range(1, 10))\n}\nclf = GridSearchCV(mnb, parameters, cv=5)\nclf.fit(X_train, y_train)",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 77,
          "data": {
            "text/plain": "GridSearchCV(cv=5, error_score='raise-deprecating',\n       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n       fit_params=None, iid='warn', n_jobs=None,\n       param_grid={'alpha': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring=None, verbose=0)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d41c6d1b548b029db8aac90f2f429011665aeece"
      },
      "cell_type": "code",
      "source": "print(\"Best parameters: \", clf.best_estimator_)\nfinal_model = clf.best_estimator_",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Best parameters:  MultinomialNB(alpha=5, class_prior=None, fit_prior=True)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52829b7e782119d9a121e7287b26a121b83b7f4d"
      },
      "cell_type": "code",
      "source": "final_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Final Accuracy: 0.84252\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3edfc3511af9c6685d09b15386be02a826e82af8"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        stopword_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": "('one', -5.511019995866638)\n('film', -5.523028145495035)\n('movie', -5.5252117358478365)\n('like', -5.789023154218585)\n('good', -5.915076944702976)\n('time', -6.006001424253158)\n('well', -6.022730184042363)\n('see', -6.037215116963731)\n('story', -6.045102481796896)\n('great', -6.049353586399379)\n\n\n\n('____________________________________', -12.606415993120331)\n('____insert', -12.606415993120331)\n('_a', -12.606415993120331)\n('_absolute', -12.606415993120331)\n('_am_', -12.606415993120331)\n('_and_', -12.606415993120331)\n('_angel_', -12.606415993120331)\n('_annie_', -12.606415993120331)\n('_any_', -12.606415993120331)\n('_anything_', -12.606415993120331)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "24f4c7c6952229cd5df57b6e4e45f584cfd692cd"
      },
      "cell_type": "markdown",
      "source": "**Using Naive Bayes with TFIDF**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d21b94e2cf69ec40007724977725728bf0b2d7d1"
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(stop_words='english', analyzer='word', ngram_range=(1, 2))\ntfidf_vectorizer.fit(reviews_train_clean)\nprint(\"Size of dictionary: \", len(tfidf_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", tfidf_vectorizer.get_feature_names())",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Size of dictionary:  1777206\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8714c1f2f179b5bd1c0fa0c538b9b19b706104f4"
      },
      "cell_type": "code",
      "source": "X_train = tfidf_vectorizer.transform(reviews_train_clean)\nX_test = tfidf_vectorizer.transform(reviews_test_clean)",
      "execution_count": 87,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ffc32e0b3d1ec38a8dea331765642f96610d973"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, target, train_size = 0.85)\n\nmnb = MultinomialNB()\nparameters = {\n    'alpha':list(range(1, 10))\n}\nclf = GridSearchCV(mnb, parameters, cv=5)\nclf.fit(X_train, y_train)",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 88,
          "data": {
            "text/plain": "GridSearchCV(cv=5, error_score='raise-deprecating',\n       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n       fit_params=None, iid='warn', n_jobs=None,\n       param_grid={'alpha': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring=None, verbose=0)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c71ec7085901f78e5208ecc82146ab49effbbf30"
      },
      "cell_type": "code",
      "source": "print(\"Best parameters: \", clf.best_estimator_)\nfinal_model = clf.best_estimator_",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Best parameters:  MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e06dfdc527377dd286440b1c09c7d89ad031515"
      },
      "cell_type": "code",
      "source": "final_model.fit(X_train, y_train)\nprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Final Accuracy: 0.85452\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f28fed1ac166c2a7472795dccbb377ddf52f627e"
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        tfidf_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n    \nprint(\"\\n\\n\")\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1be108329f24abe9f935e4d6e78ec629522f048b"
      },
      "cell_type": "code",
      "source": "Naive Bayes is a very good algorithm for text classification and considered as baseline. Basically for text classification NB is benchmark where accuracy of other algorithms are compared with NB.",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
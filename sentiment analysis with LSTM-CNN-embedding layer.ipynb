{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16ef3e4f85a17b9d756739c763555fcc5591ee07"
      },
      "cell_type": "code",
      "source": "reviews_train = []\nfor line in open('../input/movie_data/movie_data/full_train.txt', 'r'):\n    \n    reviews_train.append(line.strip())\n    \nreviews_test = []\nfor line in open('../input/movie_data/movie_data/full_test.txt', 'r'):\n    \n    reviews_test.append(line.strip())\n    \ntarget = [1 if i < 12500 else 0 for i in range(25000)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75d321e34c7919e7c6b330fc6fc2193dae34056e"
      },
      "cell_type": "code",
      "source": "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\nREPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\nNO_SPACE = \"\"\nSPACE = \" \"\n\ndef preprocess_reviews(reviews):\n    \n    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n    \n    return reviews\n\nreviews_train_clean = preprocess_reviews(reviews_train)\nreviews_test_clean = preprocess_reviews(reviews_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8e392d4fc9a5d126813b408d5725f7b3c123fb2"
      },
      "cell_type": "code",
      "source": "from nltk.corpus import stopwords\n\nenglish_stop_words = stopwords.words('english')\n\ndef remove_stop_words(corpus):\n    removed_stop_words = []\n    for review in corpus:\n        removed_stop_words.append(\n            ' '.join([word for word in review.split() \n                      if word not in english_stop_words])\n        )\n    return removed_stop_words",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f0b9ddc020bcfe7861b2ea8e0041a1845ef3d12"
      },
      "cell_type": "code",
      "source": "no_stop_words_train = remove_stop_words(reviews_train_clean)\nno_stop_words_test = remove_stop_words(reviews_test_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a94dc0820953bf562e5b5eccf9afd4dd7f965fc1"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\n\nvocab_size = 5000\nmax_words = 500\ntokenizer = Tokenizer(num_words=vocab_size)\ntokenizer.fit_on_texts(no_stop_words_train)\n\nX_train = tokenizer.texts_to_sequences(no_stop_words_train)\nX_test = tokenizer.texts_to_sequences(no_stop_words_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "76a734138d76a8ba247de115cc2113b894cf86b9"
      },
      "cell_type": "code",
      "source": "#stopword_vectorizer = CountVectorizer()\n#stopword_vectorizer.fit(no_stop_words_train)\n#print(\"Size of dictionary: \", len(stopword_vectorizer.get_feature_names()))\n#print(\"Words in dictionary: \", stopword_vectorizer.get_feature_names())\n\n#X_train = stopword_vectorizer.transform(no_stop_words_train).toarray()\n#X_test = stopword_vectorizer.transform(no_stop_words_test).toarray()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60969bb2b7e3123e2a7cefbb87cf49fd9ca5187c"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing import sequence\nX_train = sequence.pad_sequences(X_train, maxlen=max_words)\nX_test = sequence.pad_sequences(X_test, maxlen=max_words)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba40a096e9038554f7e737a1d17fb9ecfb40226c"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X_train, target, train_size = 0.85)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b779cc10f7d36c2ccf3226ccfeed51944e44799"
      },
      "cell_type": "code",
      "source": "X_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa27426d90d77c2b17a9d00ca9f5d1f5b8d2da01"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, MaxPool1D\nfrom keras.preprocessing import sequence\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1)\nearlt_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f8febb2937044c2d64c4284bf9c6fa9daa278cf3"
      },
      "cell_type": "markdown",
      "source": "**Model 1**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a9f972d9e45a3fe415555300a3912fdbe9adc07"
      },
      "cell_type": "code",
      "source": "model = Sequential()\n#model.add(Embedding(len(stopword_vectorizer.get_feature_names()), 32, input_length=max_words))\nmodel.add(Embedding(vocab_size, 32, input_length=max_words))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9cbb0c92f591ff74c880acb95e8f33cfabcfe97"
      },
      "cell_type": "code",
      "source": "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=15, batch_size=128, verbose=1, callbacks=[reduce_lr, earlt_stopper]).history",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "39e03bbd9d8f1f7b5445602cf5104320db5dd3eb"
      },
      "cell_type": "code",
      "source": "plt.plot(history['acc'], linewidth=2, label='Train')\nplt.plot(history['val_acc'], linewidth=2, label='Test')\nplt.legend(loc='upper right')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f1d515e8d1564fa6935689d1543fdeb2495284ea"
      },
      "cell_type": "markdown",
      "source": "**Model 2**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "727eb7c53b0c06be8e2fbdb78e2278b2b91c77a0"
      },
      "cell_type": "code",
      "source": "embedding_size = 32\nmodel=Sequential()\nmodel.add(Embedding(vocab_size, embedding_size, input_length=max_words))\nmodel.add(Dropout(0.2))\nmodel.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(MaxPool1D(pool_size = 2))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d062b7b6e307ed6e1726f7f0053c4fab3d3b165"
      },
      "cell_type": "code",
      "source": "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=128, verbose=1, callbacks=[reduce_lr, earlt_stopper]).history",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7cb3f455cdd57f75d7bf617051d42fabf9db3a2"
      },
      "cell_type": "code",
      "source": "plt.plot(history['acc'], linewidth=2, label='Train')\nplt.plot(history['val_acc'], linewidth=2, label='Test')\nplt.legend(loc='upper right')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a1f0a00fb41b1ca558e65f2a48dfe9b8c8b69c75"
      },
      "cell_type": "markdown",
      "source": "**Model 3**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11d246ee83e6598e13deb860c40a2d560ed2eb37"
      },
      "cell_type": "code",
      "source": "embedding_vector_length = 32\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_vector_length, input_length=max_words))\nmodel.add(LSTM(100, activation = 'tanh', recurrent_activation='hard_sigmoid', dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca134052ae12a5305610e90dbaed3722d82ed376"
      },
      "cell_type": "code",
      "source": "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=128, verbose=1, callbacks=[reduce_lr, earlt_stopper]).history",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bad819b2c07899f6d09c08aa19d822e815477bf4"
      },
      "cell_type": "code",
      "source": "plt.plot(history['acc'], linewidth=2, label='Train')\nplt.plot(history['val_acc'], linewidth=2, label='Test')\nplt.legend(loc='upper right')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cae0191c9cf526158c92a12e297db980643a1a18"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}